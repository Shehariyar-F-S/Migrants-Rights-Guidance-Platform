# Migrants-Rights-Guidance-Platform

A local Retrievalâ€‘Augmented Generation (RAG) assistant that answers questions about migrantsâ€™ rights and procedures using official legal PDFs (for example, the Dublin Regulation) as its only knowledge source.
The system runs entirely on a laptop using openâ€‘source tools (Ollama + Llama 3, ChromaDB, LangChain, Streamlit).

ğŸš€ Features
Domainâ€‘specific legal assistant for EU asylum and migration documents (starting with the Dublin Regulation)

Localâ€‘only stack: all documents, embeddings, and LLM inference run on your machine

Multiâ€‘PDF support: drop multiple PDFs into a folder and index them together

RAG pipeline:

PDF â†’ text extraction â†’ chunking

Sentenceâ€‘Transformer embeddings â†’ Chroma vector store

Topâ€‘k retrieval â†’ Llama 3 via Ollama for grounded answers

Two interfaces:

CLI Q&A (terminal)

Web chat UI built with Streamlit

ğŸ§± Architecture
1. Indexing (offline)
Load all PDFs from a data/ folder (for example, DUBLIN REGULATIONS.pdf and other guides)

Split pages into overlapping text chunks

Create dense embeddings with a Sentenceâ€‘Transformer model (for example, all-MiniLM-L6-v2)

Store embeddings, chunk texts, and metadata (including source filename) in a persistent ChromaDB collection (for example, dublin_chroma)

2. Retrieval & generation (online)
For each user question:

Embed the question with the same Sentenceâ€‘Transformer model

Retrieve topâ€‘k similar chunks from Chroma

Build a legalâ€‘style prompt: â€œanswer only from this context; if not present, say you donâ€™t knowâ€

Call Llama 3 running locally via Ollama to generate a concise answer

Optionally display which PDF each answer is grounded in

3. User interfaces
CLI: ask questions in the terminal and receive answers as plain text

Web UI (Streamlit): chatâ€‘style interface with history, suitable for demoing in a browser

ğŸ“‚ Project structure
Example layout (adjust if your repo differs):

text
.
â”œâ”€â”€ app.py                # Streamlit web UI
â”œâ”€â”€ index_pdfs.py         # Oneâ€‘time (or occasional) indexing script
â”œâ”€â”€ query_cli.py          # CLI questionâ€‘answer interface
â”œâ”€â”€ dublin_rag.py         # Core RAG logic (rag_answer function)
â”œâ”€â”€ requirements.txt
â”œâ”€â”€ README.md
â”œâ”€â”€ data/                 # Input PDFs (not committed if sensitive)
â”‚   â”œâ”€â”€ DUBLIN REGULATIONS.pdf
â”‚   â””â”€â”€ other_documents.pdf
â””â”€â”€ db/                   # ChromaDB persistent data (generated)
ğŸ”§ Setup
1. Clone the repository
bash
git clone https://github.com/<your-username>/migrants-rights-guidance-platform.git
cd migrants-rights-guidance-platform
2. (Optional) Create and activate a virtual environment
bash
python -m venv .venv
# macOS / Linux
source .venv/bin/activate
# Windows
# .venv\Scripts\activate
3. Install dependencies
bash
pip install -r requirements.txt
A typical requirements.txt:

text
langchain
langchain-community
chromadb
sentence-transformers
pypdf
streamlit
ollama
4. Install and configure Ollama
Install Ollama from its official site

Pull the Llama 3 model:

bash
ollama pull llama3
Test that it runs:

bash
ollama run llama3
5. Add PDFs
Place your legal PDFs inside the data/ directory, for example:

text
data/
 â”œâ”€â”€ DUBLIN REGULATIONS.pdf
 â”œâ”€â”€ guide_1.pdf
 â””â”€â”€ guide_2.pdf
ğŸ§® Step 1 â€“ Index the documents
Run the indexing script (once or whenever the PDFs change):

bash
python index_pdfs.py
This script:

Iterates over all *.pdf files in data/

Extracts text and splits it into chunks

Embeds each chunk with all-MiniLM-L6-v2

Stores embeddings + text + metadata in a ChromaDB collection under db/

ğŸ’¬ Step 2 â€“ Ask questions (CLI)
Use the terminal interface:

bash
python query_cli.py
Example interaction:

text
Your question (or 'exit'): Who is responsible for examining an asylum application under the Dublin Regulation?

Answer:
<model answer here>

Your question (or 'exit'):
ğŸŒ Step 3 â€“ Web UI (Streamlit)
Start the Streamlit app:

bash
streamlit run app.py
Open the URL shown in the terminal (usually http://localhost:8501).

With the web app you can:

Ask questions about the Dublin Regulation and related documents

See answers generated by Llama 3, grounded in the indexed PDFs

Optionally see which source document each answer used

ğŸ” Example questions
You can try questions like:

â€œWhich country is responsible for examining my asylum application under the Dublin rules?â€

â€œWhat happens if my fingerprints were taken in another EU country?â€

â€œHow are family members treated in the Dublin procedure?â€

â€œAre there special rules for unaccompanied minors?â€

ğŸ§± Tech stack
Language model: Llama 3 (via Ollama, running locally)

Orchestration: LangChain

Vector database: ChromaDB (persistent, local)

Embeddings: Sentenceâ€‘Transformers (all-MiniLM-L6-v2)

PDF processing: PyPDF / LangChain PyPDFLoader

UI: Streamlit (web), Python CLI (terminal)

ğŸŒ± Future work
Add multilingual support (for example, English and German answers)

Expose articleâ€‘level citations and links back into the PDFs

Extend beyond the Dublin Regulation to broader EU and national migration law

Add authentication and roleâ€‘based access for NGOs or caseworkers

ğŸ¤ Contributing
Contributions and ideas are welcome:

Improving prompts

Adding more document collections

Enhancing the UI/UX

Adding evaluation scripts for answer quality

